# Testing model {.unnumbered}

```{r, echo=FALSE}
dem <- terra::rast("Data/PF_DTM3.tif")
multi_pts <- terra::vect("Data/multi_pts.shp")
simple_pts <- terra::vect("Data/simple_pts.shp")
grad20 <- terra::rast("Data/grad20.tif")
prof20 <- terra::rast("Data/prof20.tif")
plan20 <- terra::rast("Data/plan20.tif")
grad100 <- terra::rast("Data/grad100.tif")
prof100 <- terra::rast("Data/prof100.tif")
plan100 <- terra::rast("Data/plan100.tif")
dev100 <- terra:: rast("Data/dev100.tif")
twi10 <- terra::rast("Data/twi10.tif")
in_rasts <- list(grad20 = grad20, prof20 = prof20,
                 plan20 = plan20, grad100 = grad100,
                 prof100 = prof100, plan100 = plan100,
                 dev100 = dev100, twi10 = twi10)
load("Data/fun.RData")
```

So we have model predictions on the whole area. But just how accurate are these predictions? That is what the `CV_err` function is here to find out. The function uses cross validation, which is done by splitting the data into a certain number of chunks, called folds (which is represented by the `kfold` parameter), sets one aside to be the test data, trains the model on the rest of the data, and then cross-references the model's predictions against the test data. More explanation on how it works can be found [here](https://machinelearningmastery.com/k-fold-cross-validation/). One thing to note is these estimates might be slight overestimates (since the models here are not built using all of the data).

The estimates will be produced as a printed output, meaning it does not need to be saved to a variable.

## Parameters

The inputs for this function are almost the exactly the same as the `build_model` function, with one addition, `kfold`, the number of folds used in cross-validation.

| Inputs             | Descriptions                                                                                                                                                               |
|--------------|----------------------------------------------------------|
| `in_rasts`         | List input that contains all the rasters that are chosen to be included in the model                                                                                       |
| `poly_inputs`      | List input that contains the polygons that are chosen to be included in the model, if any                                                                                  |
| `train`            | Spatial vector input of the training points                                                                                                                                |
| `ref_raster`       | Spatial raster input of the reference raster, which is used to align all of the other inputs. The DEM is usually a good choice here                                        |
| `model_type`       | String input indicating type of machine learning model. Options include "forest", "tree", "glm", and "knn"                                                                 |
| `model_params`     | List input representing necessary parameters to the model. Depending on the model, it may require an extra input, such as the number of trees or number of neighbors.      |
| `class_field_name` | String input indicating the field where the wetland classification is. If calculated training points using the `build_train_pts` function above, this input may be skipped |
| `kfold`            | Numeric input indicating number of folds data is split into. Represents number of times we test the model                                                                  |

## Examples of use

The function has the same inputs as the `build_model` functions. However, there is one more feature to customize, which is `k_folds`, or the number of times the cross validation is run. The default for the function is `kfolds = 5`

```{r}
CV_err(in_rasts = in_rasts, train = multi_pts, ref_raster = dem)
CV_err(in_rasts = in_rasts, train = simple_pts, ref_raster = dem)
```

As we can tell above, the binary model is doing a much better job of prediction than the multi-class model
