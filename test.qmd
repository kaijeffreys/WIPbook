# Testing model {.unnumbered}

```{r, echo=FALSE}
dem <- terra::rast("Data/PF_DTM3.tif")
multi_pts <- terra::vect("Data/multi_pts.shp")
simple_pts <- terra::vect("Data/simple_pts.shp")
elev1 <- list(grad20 = terra::rast("Data/grad20.tif"),
              prof20 = terra::rast("Data/prof20.tif"),
              plan20 = terra::rast("Data/plan20.tif"))
elev2 <- list(grad100 = terra::rast("Data/grad100.tif"),
              prof100 = terra::rast("Data/prof100.tif"),
              plan100 = terra::rast("Data/plan100.tif"))
elev3 <- list(twi10 = terra::rast("Data/twi10.tif"))
load("Data/fun.RData")
```

So we have model predictions on the whole area. But just how accurate are these predictions? That is what the `CV_err` function is here to find out. The function uses cross validation, which is done by splitting the data into a certain number of chunks, called folds (which is represented by the `kfold` parameter), sets one aside to be the test data, trains the model on the rest of the data, and then cross-references the model's predictions against the test data. More explanation on how it works can be found [here](https://machinelearningmastery.com/k-fold-cross-validation/). One thing to note is these estimates might be slight overestimates (since the models here are not built using all of the data).

The estimates will be produced as a printed output, meaning it does not need to be saved to a variable.

## Parameters

The inputs for this function are almost the exactly the same as the `build_model` function, with one addition, `kfold`, the number of folds used in cross-validation.

| Inputs             | Descriptions                                                                                                                                                               |
|-----------------|-------------------------------------------------------|
| `in_rasts`         | List input that contains all the rasters that are chosen to be included in the model                                                                                       |
| `poly_inputs`      | List input that contains the polygons that are chosen to be included in the model, if any                                                                                  |
| `train`            | Spatial vector input of the training points                                                                                                                                |
| `ref_raster`       | Spatial raster input of the reference raster, which is used to align all of the other inputs. The DEM is usually a good choice here                                        |
| `model_type`       | String input indicating type of machine learning model. Options include "forest", "tree", "glm", and "knn"                                                                 |
| `model_params`     | List input representing necessary parameters to the model. Depending on the model, it may require an extra input, such as the number of trees or number of neighbors.      |
| `class_field_name` | String input indicating the field where the wetland classification is. If calculated training points using the `build_train_pts` function above, this input may be skipped |
| `kfold`            | Numeric input indicating number of folds data is split into. Represents number of times we test the model                                                                  |

## Examples of use

The function has the same inputs as the `build_model` functions. However, there is one more feature to customize, which is `k_folds`, or the number of times the cross validation is run. The default for the function is `kfolds = 5`

```{r}
CV_err(in_rasts = c(elev1, elev2, elev3), train = multi_pts,
       ref_raster = dem)
CV_err(in_rasts = c(elev1, elev2, elev3), train = simple_pts,
       ref_raster = dem)
```

As we can tell above, the binary model is doing a much better job of prediction than the multi-class model