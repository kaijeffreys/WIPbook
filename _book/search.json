[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Guide to Running the Wetland Intrinsic Potential (WIP) Tool in R",
    "section": "",
    "text": "Preface\nWetland inventories are essential for tracking loss of wetlands. The WIP tool was developed to identify wetlands that are missing from existing wetland inventories. Our wetland indicator framework, which includes spatial variables representing vegetation, hydrology, soils, and multi-scale topographic attributes can be used to quantify probability of wetland occurrence, as well as predict the type of wetland. Our wetland indicator framework provides a flexible approach that can be adapted to identify diverse wetland types across varied landscapes. The reasoning behind this framework is shown below\n\nThe following article provides a skeleton of how to run this tool in the R programming language. It must be noted that there are some things, including many of the wetland indicators, like vegetation and soils, that must be obtained externally for now. However, the development of topographical indices and everything to do with the building and running of the model, can be run in R.\n\n\n\nExample of WIP Tool in Hoh Rainforest"
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "Setup",
    "section": "",
    "text": "Install base R from CRAN\nInstall R Studio from Posit\nRun RStudio (if needed, a quality introduction to R can be found here), then install packages that may or not be needed in the code chunk below. More information on each packages as follows:\n\nThe main package for spatial data and statistics: terra. The WIP tool will simply not run if terra is not installed\nThe MultiscaleDTM package is a necessity if one wants to calculate the surface metrics (such as gradient, curvature, etc.) within R\nThe packages randomForest, caret, and nnet may or may not need to be installed, depending on the type of model you want to run. I recommend installing all of them just in case\n\n\n\ninstall.packages(\"terra\")\ninstall.packages(\"MultiscaleDTM\")\ninstall.packages(\"randomForest\")\ninstall.packages(\"caret\")\ninstall.packages(\"nnet\")\n\n\nLoad in the functions. Since the WIP tool is not a package as of yet, that means to run the tool, you will have to load the functions by running them directly in R. The functions are all in the Functions section towards the end of this document\n(Optional) Load in the data that will be used in the tool. This step is optional because all of the functions used in the WIP tool can receive file names as inputs. However, typing out file names over and over again can be a drag, so loading them in once can be the superior option.\n\n\ndem &lt;- terra::rast(\"Data/PF_DTM3.tif\")\nregion &lt;- terra::vect(\"Data/PF_studyarea.shp\")\nwetlands &lt;- terra::vect(\"Data/PF_wetlands.shp\")\n\nThe data that we loaded above to use for the book is from an area in Eatonville, WA (near Mount Rainier) called Pack Forest. It is a small land mass (making it ideal for an example), with four classified wetlands: Riverine, Freshwater Emergent Wetland, Freshwater Forested/Shrub Wetland, and Freshwater Pond. The three variables that were just loaded are the Digital Elevation Model (DEM), a polygon file describing a area, and a polygon file describing wetlands within that area, respectively."
  },
  {
    "objectID": "train_pts.html#parameters",
    "href": "train_pts.html#parameters",
    "title": "Training Points",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\nInputs\nDescription\n\n\n\n\nregion_poly\nPolygon (shape file) input that contains the shape of the whole area of interest\n\n\nwet_poly\nPolygon input that contains areas where the (known) wetlands are located\n\n\nmulti_class\nBinary variable indicating whether or not to return points from each of the wetland types or just have binary wetland/non-wetland points\n\n\nwet_types\nVector input that lists all the types of wetlands we are considering draw sample points of that are listed in the wet_poly input\n\n\nwet_field\nString input indicating what the field name of the type of wetland in wet_poly is. The default is “WETLAND_TY”, given that is the name NWI uses\n\n\nsample_points\nVector indicating number of points to sample that are wet and non-wetland. First element in vector is the number of wetland points and second element is the number of non-wetland\n\n\nexport\nBinary parameter that determines whether or not the function exports the output to a file"
  },
  {
    "objectID": "train_pts.html#running-training-points",
    "href": "train_pts.html#running-training-points",
    "title": "Training Points",
    "section": "Running training points",
    "text": "Running training points\n\nsimple_pts &lt;- build_train_pts(region_poly = region,\n                             wet_poly = wetlands,\n                             wet_types = c(\"Riverine\", \n                                           \"Freshwater Emergent Wetland\",\n                                           \"Freshwater Forested/Shrub Wetland\",\n                                           \"Freshwater Pond\"),\n                             multi_class = FALSE)\n\n\nmulti_pts &lt;- build_train_pts(region_poly = region,\n                             wet_poly = wetlands,\n                             wet_types = c(\"Riverine\", \n                                           \"Freshwater Emergent Wetland\",\n                                           \"Freshwater Forested/Shrub Wetland\",\n                                           \"Freshwater Pond\"),\n                             sample_points = c(20, 150),\n                             multi_class = TRUE)\n\nIf you run this function, as is done above, it returns a Spatvector input of points, with some labeled as UPL (for upland) and others either labeled as WET or, if chosen multi_class, the particular type of wetland (such as Freshwater Pond), as shown below.\n\nmulti_pts\n\n class       : SpatVector \n geometry    : points \n dimensions  : 230, 1  (geometries, attributes)\n extent      : 551155.6, 557066, 5184777, 5189817  (xmin, xmax, ymin, ymax)\n coord. ref. : NAD83 / UTM zone 10N (EPSG:26910) \n names       :    class\n type        :   &lt;fact&gt;\n values      : Riverine\n               Riverine\n               Riverine\n\n\nHere’s a visual of what the training points look like\n\n\n\n\n\nIf you run the function without specifying the wet_type, it might still run (especially if the data was obtained from NWI), but it will also likely give warnings, for some wetland types that are not present in the file, as shown below.\n\nbuild_train_pts(region, wetlands)\n\n class       : SpatVector \n geometry    : points \n dimensions  : 200, 1  (geometries, attributes)\n extent      : 551161.9, 556979, 5184869, 5189818  (xmin, xmax, ymin, ymax)\n coord. ref. : NAD83 / UTM zone 10N (EPSG:26910) \n names       :  class\n type        : &lt;fact&gt;\n values      :    WET\n                  WET\n                  WET"
  },
  {
    "objectID": "train_pts.html#external-training-points",
    "href": "train_pts.html#external-training-points",
    "title": "Training Points",
    "section": "External Training Points",
    "text": "External Training Points\nIf you obtained a set of training points through some sort of external source, the following functions will still work, as long as there are points on the same area as what is set as the ref_raster, which will be discussed more later. In other words, the training points can use a different projection system or spatial extent and still work"
  },
  {
    "objectID": "metrics.html#types-of-metrics",
    "href": "metrics.html#types-of-metrics",
    "title": "Surface Metrics",
    "section": "Types of Metrics",
    "text": "Types of Metrics\nThere are five types of surface metrics that we are currently able to calculate here: gradient, planar curvature, profile curvature, local relief, and topographical wetness index (TWI).\n\nGradient: essentially just the rate of change in elevation\nProfile curvature: the curvature in the direction of the maximum slope\nPlanar curvature: the curvature that is perpendicular to the direction of the maximum slope (sideways curvature)\nLocal relief (DEV): is the representation of where a spot is in elevation in comparison to its surroundings\nTWI: essentially a model of how water will flow beneath the surface, calculated from topography attributes\n\nTo calculate the above metrics, we have two different choices of function. One calculates the metrics in R, while the other function connects to a set of external files, called Executable Files."
  },
  {
    "objectID": "surface_met1.html#parameters",
    "href": "surface_met1.html#parameters",
    "title": "Using Executable files",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\nInputs\nDescription\n\n\n\n\nlen\nThe length that the metrics are calculated at\n\n\nmetrics\nVector indicating which metrics to calculate. Options include “grad”, “prof”, “plan”, and “dev”\n\n\ndem_dir\nString (text) input that indicates the file directory of the file that contains the DEM\n\n\nexec_dir\nString input that indicates the file directory\n\n\nout_dir\nString input of the directory where the output is\n\n\nre_sample\nNumber indicating the re-sampling rate for the DEV/local relief"
  },
  {
    "objectID": "surface_met1.html#using-function-example",
    "href": "surface_met1.html#using-function-example",
    "title": "Using Executable files",
    "section": "Using function example",
    "text": "Using function example\n\nsurface_met1(len = 100, dem_dir = \"Data/PF_DTM3.tif\",\n             metrics = c(\"grad\", \"prof\", \"plan\"),\n             exec_dir = \"../ExecutableFiles\")\n\nThe functions creates a .txt file named input_makeGrids (or input_localRelief for DEV) which, as the name suggests, is an input file for the Executable Files. It lists all the important file directories (including the outputs), as well as the length scale that the metrics will be calculated at.\n\nVisuals of example\nHere is what a map of gradient looks like at 100 meter length scale, calculated above.\n\n\n\n\n\nAs for the curvatures, the minute differences might be hard to see on a visualization, but rest assured, the assumed minute differences are still important in the models that are calculated later on."
  },
  {
    "objectID": "surface_met.html#parameters",
    "href": "surface_met.html#parameters",
    "title": "Completely in R",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\nInputs\nDescription\n\n\n\n\nDEM\nAs the name suggests, this input is the DEM/DTM\n\n\nlen\nNumber input represents the length at which the metric is calculated\n\n\nelev_dev\nVector input of selection of metrics. The choices are “grad”, “prof”, “plan”, “dev”, “twi”\n\n\nexport\nThis is a binary (true/false) parameter that determines whether or not the function exports the output(s) to a file"
  },
  {
    "objectID": "surface_met.html#using-the-function",
    "href": "surface_met.html#using-the-function",
    "title": "Completely in R",
    "section": "Using the function",
    "text": "Using the function\n\nelev1 &lt;- surface_met(dem, len = 20, elev_dev = c(\"grad\", \"prof\", \"plan\"))\n\n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\nelev2 &lt;- surface_met(dem, len = 100, elev_dev = c(\"grad\", \"prof\", \"plan\"))\n\n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\nelev3 &lt;- surface_met(dem, len = 10, elev_dev = c(\"twi\"))\n\nA progress bar is printed below a few of the functions, in case you were wondering what those odd lines were. This is added so that the user can have some semblance of how much is left to run. Most of the functions within the entirety of the tool do something similar, as they will often take some time to run.\n\nVisualizing output\n\n\n\n\n\nAs we can see, the shape is similar to the one calculated by the Executable Files, though the scale is a little different\nFor the types of curvature, the edges are puffed up, as shown below.\n\n\n\n\n\nThis is done to ensure that data is not eliminated, since the other option would make it so that plenty of area around the edges would be eliminated, exponentially so with larger length scales. These will get smoothed out later on in the WIP process, so the final output will not look like this.\nOne last visualization that you might find interesting is how the TWI looks, so this is shown below."
  },
  {
    "objectID": "build_model.html#model-options",
    "href": "build_model.html#model-options",
    "title": "Build Model",
    "section": "Model options",
    "text": "Model options\nThe model options are decision tree, random forest, logistic regression, and k-nearest neighbors. More on these types of models in the coming pages The default setting is to run random forest with n=200 trees. To change this, the user would just need to type model_type = and choose their selection of c(\"forest\", \"tree\", \"glm\", \"knn\").\nAlso, depending on the model choice, you might also have to add an extra input, model_params. If the choice is knn, then you would have to add in the number of neighbors. For example, if you want to use ten neighbors, just type in model_params = list(k = 10). If you want to use a different number of tress in the random forest than n=200, just type in model_params = list(ntree = ) , with the selected choice of trees after the equal sign."
  },
  {
    "objectID": "build_model.html#parameters",
    "href": "build_model.html#parameters",
    "title": "Build Model",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\nInput\nDescription\n\n\n\n\nin_rasts\nList input that contains all the rasters that are chosen to be included in the model\n\n\npoly_inputs\nList input that contains the polygons that are chosen to be included in the model, if any\n\n\ntrain\nSpatial vector input of the training points\n\n\nref_raster\nSpatial raster input of the reference raster, which is used to align all of the other inputs. The DEM is usually a good choice here\n\n\nmodel_type\nString input indicating type of machine learning model. Options include “forest”, “tree”, “glm”, and “knn”\n\n\nmodel_params\nList input representing necessary parameters to the model. Depending on the model, it may require an extra input, such as the number of trees or number of neighbors.\n\n\nclass_field_name\nString input indicating the field where the wetland classification is. If calculated training points using the build_train_pts function above, this input may be skipped. However, very important if training points came externally"
  },
  {
    "objectID": "tree.html#description",
    "href": "tree.html#description",
    "title": "Decision Tree",
    "section": "Description",
    "text": "Description\nA decision tree is a method of machine learning that works a lot like a flow chart. Using the features, or input data, the tree then conducts tests on the data. An example of one of these tests, would be if the gradient at 100 meters is greater than 0.5, or whether the planar curvature is greater than 0.05, or if TWI is higher than zero. After a test, then depending on its result, the tree either assigns a class or checks another test. The tree keeps conducting tests until it assigns a class to the observation. A diagram of how this whole system works can be found below"
  },
  {
    "objectID": "tree.html#example-of-use",
    "href": "tree.html#example-of-use",
    "title": "Decision Tree",
    "section": "Example of use",
    "text": "Example of use\n\nmulti_mod &lt;- build_model(in_rasts = c(elev1, elev2, elev3),\n                         train = multi_pts, ref_raster = dem,\n                         class_field_name = \"class\",\n                         model_type = \"tree\")\n\n[1] \"Formatting inputs\"\n[1] \"Setting up training data\"\n[1] \"Building model\"\n[1] \"Done!\"\n\nsimple_mod &lt;- build_model(in_rasts = c(elev1, elev2, elev3),\n                         train = simple_pts, ref_raster = dem,\n                         model_type = \"tree\")\n\n[1] \"Formatting inputs\"\n[1] \"Setting up training data\"\n[1] \"Building model\"\n[1] \"Done!\"\n\n\nThe returned object is a randomForest object (more on why on the next page), which contains a large amount of information. If run, as is done below, it returns the estimated error as well as a confusion matrix on the training data\n\nmulti_mod\n\n\nCall:\n randomForest(formula = class ~ ., data = df_train, ntree = 1) \n               Type of random forest: classification\n                     Number of trees: 1\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 44.09%\nConfusion matrix:\n                                  Freshwater Emergent Wetland\nFreshwater Emergent Wetland                                 1\nFreshwater Forested/Shrub Wetland                           0\nFreshwater Pond                                             1\nRiverine                                                    0\nUPL                                                         4\n                                  Freshwater Forested/Shrub Wetland\nFreshwater Emergent Wetland                                       0\nFreshwater Forested/Shrub Wetland                                 0\nFreshwater Pond                                                   0\nRiverine                                                          1\nUPL                                                               5\n                                  Freshwater Pond Riverine UPL class.error\nFreshwater Emergent Wetland                    10        0   1   0.9166667\nFreshwater Forested/Shrub Wetland               3        0   3   1.0000000\nFreshwater Pond                                 2        0   0   0.3333333\nRiverine                                        3        2   3   0.7777778\nUPL                                             6        1  47   0.2539683"
  },
  {
    "objectID": "forest.html#description",
    "href": "forest.html#description",
    "title": "Random Forest",
    "section": "Description",
    "text": "Description\nA random forest is a model that generates a large number of decision trees (hence the name). To calculate probabilities, the model checks the decisions and then calculates the proportion of the trees that chose each class. Those proportions are the estimated probabilities. To make an overall prediction, the model just takes the class with the highest amount trees that decided in its favor."
  },
  {
    "objectID": "forest.html#examples-of-use",
    "href": "forest.html#examples-of-use",
    "title": "Random Forest",
    "section": "Examples of Use",
    "text": "Examples of Use\n\nmulti_mod &lt;- build_model(in_rasts = c(elev1, elev2, elev3),\n                         train = multi_pts, ref_raster = dem)\n\n[1] \"Formatting inputs\"\n[1] \"Setting up training data\"\n[1] \"Building model\"\n[1] \"Done!\"\n\nsimple_mod &lt;- build_model(in_rasts = c(elev1, elev2, elev3),\n                         train = simple_pts, ref_raster = dem)\n\n[1] \"Formatting inputs\"\n[1] \"Setting up training data\"\n[1] \"Building model\"\n[1] \"Done!\"\n\n\nSince they are very similar algorithms, the returned output for random forest models is the same as with trees, as we can see from the printed output below:\n\nmulti_mod\n\n\nCall:\n randomForest(formula = class ~ ., data = df_train, ntree = model_params$ntree) \n               Type of random forest: classification\n                     Number of trees: 200\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 30.41%\nConfusion matrix:\n                                  Freshwater Emergent Wetland\nFreshwater Emergent Wetland                                 7\nFreshwater Forested/Shrub Wetland                           1\nFreshwater Pond                                             1\nRiverine                                                    2\nUPL                                                         4\n                                  Freshwater Forested/Shrub Wetland\nFreshwater Emergent Wetland                                       0\nFreshwater Forested/Shrub Wetland                                 1\nFreshwater Pond                                                   3\nRiverine                                                          1\nUPL                                                               4\n                                  Freshwater Pond Riverine UPL class.error\nFreshwater Emergent Wetland                     2        0  11  0.65000000\nFreshwater Forested/Shrub Wetland               2        1  12  0.94117647\nFreshwater Pond                                 8        0   7  0.57894737\nRiverine                                        0        4  12  0.78947368\nUPL                                             0        3 131  0.07746479"
  },
  {
    "objectID": "glm.html#description",
    "href": "glm.html#description",
    "title": "Logistic Regression",
    "section": "Description",
    "text": "Description\nLogistic regression is another type of machine learning model. Different from the first two models, logistic regression is much more mathematically involved. In short, it tries to find relationships between each field of input data and the resulting class (i.e. finding connections between gradient and wetland type). Using these relationships, it then creates a regression formula (similar to the slope equation \\(y = mx+b\\) in Algebra) that is then used to probabilities. Then, whichever class is calculated to have highest probability is what is the predicted outcome.\nOne caveat of logistic regression is that it assumes that each of the input data is independent of each other. However, this is often the case, especially using spatial data. As a result, the predictions/probabilities could end up looking a little unsual, if not careful."
  },
  {
    "objectID": "glm.html#examples-of-use",
    "href": "glm.html#examples-of-use",
    "title": "Logistic Regression",
    "section": "Examples of Use",
    "text": "Examples of Use\n\nmulti_mod &lt;- build_model(in_rasts = c(elev1, elev2, elev3),\n                         train = multi_pts, ref_raster = dem,\n                         model_type = \"glm\")\n\n[1] \"Formatting inputs\"\n[1] \"Setting up training data\"\n[1] \"Building model\"\n# weights:  45 (32 variable)\ninitial  value 349.248027 \niter  10 value 223.826226\niter  20 value 195.529526\niter  30 value 188.498465\niter  40 value 184.766843\niter  50 value 183.599588\niter  60 value 181.373417\niter  70 value 179.208432\niter  80 value 178.122418\niter  90 value 176.997883\niter 100 value 176.512240\nfinal  value 176.512240 \nstopped after 100 iterations\n[1] \"Done!\"\n\nsimple_mod &lt;- build_model(in_rasts = c(elev1, elev2, elev3),\n                          train = simple_pts, ref_raster = dem,\n                          model_type = \"glm\")\n\n[1] \"Formatting inputs\"\n[1] \"Setting up training data\"\n[1] \"Building model\"\n[1] \"Done!\"\n\n\nReturned is a list object, which contains lots and lots of information, including the predicted values of the training data, different levels of accuracy assessments, and the coefficients. These coefficients are a measure of the relationship between that data field and the class. Farther the coefficient is from zero, the larger the amount of change is supposed to be when picking between classes.\nRunning the object in console, like done below, shows us these coefficients\n\nsimple_mod\n\n\nCall:  glm(formula = class ~ ., family = \"binomial\", data = df_train)\n\nCoefficients:\n(Intercept)       grad20       prof20       plan20      grad100      prof100  \n -6.695e-01   -7.598e+00   -1.306e+01   -1.149e+02   -1.749e+00   -2.549e+02  \n    plan100        twi10  \n -1.263e+02    3.905e-05  \n\nDegrees of Freedom: 178 Total (i.e. Null);  171 Residual\nNull Deviance:      185.1 \nResidual Deviance: 133.5    AIC: 149.5"
  },
  {
    "objectID": "knn.html#description",
    "href": "knn.html#description",
    "title": "K-Nearest Neighbors",
    "section": "Description",
    "text": "Description\nLast, but not least, we have reached the k-Nearest Neighbors machine learning algorithm. This one (may) be the easiest to comprehend. How it works is that it finds a certain number of observations, \\(k\\) to be exact, that have features (the input data) that most closely match the observation we are trying to predict. We will call these close observations neighbors. Using those neighbors, the model predicts the class by picking the class that has the highest number of neighbors. For probabilities, it uses the proportion of neighbors of that class out of the total. Here is an example below.\n\n\n\n\n\nTwo classes of train data; gold diamond is new observation\n\n\n\n\nFrom the example above, we see how the decision can change with different levels of \\(k\\). If \\(k=1\\), then the decision would be Class 2, since the closest point to the diamond point is red. However, with any number of neighbors higher than \\(2\\), then decision would be Class 2.\nOne piece of advice is to normally choose either an odd number or a large number for \\(k\\). This significantly lessens the chance that there is a tie when the model makes a decision. As a result, it might also be a good idea to run it with a larger amount of training points."
  },
  {
    "objectID": "knn.html#examples-of-use",
    "href": "knn.html#examples-of-use",
    "title": "K-Nearest Neighbors",
    "section": "Examples of Use",
    "text": "Examples of Use\n\nmulti_mod &lt;- build_model(in_rasts = c(elev1, elev2, elev3),\n                       train = multi_pts, ref_raster = dem,\n                       model_type = \"knn\",\n                       model_params = list(k = 15))\n\n[1] \"Formatting inputs\"\n[1] \"Setting up training data\"\n[1] \"Building model\"\n[1] \"Done!\"\n\nsimple_mod &lt;- build_model(in_rasts = c(elev1, elev2, elev3),\n                       train = simple_pts, ref_raster = dem,\n                       model_type = \"knn\",\n                       model_params = list(k = 5))\n\n[1] \"Formatting inputs\"\n[1] \"Setting up training data\"\n[1] \"Building model\"\n[1] \"Done!\"\n\n\nThe returned output is a list that contains the input data and the predicts. As we run the object below, we can see the number the model predicted for each class\n\nmulti_mod\n\n15-nearest neighbor model\nTraining set outcome distribution:\n\n      Freshwater Emergent Wetland Freshwater Forested/Shrub Wetland \n                               20                                17 \n                  Freshwater Pond                          Riverine \n                               19                                19 \n                              UPL \n                              142"
  },
  {
    "objectID": "run_model.html#parameters",
    "href": "run_model.html#parameters",
    "title": "Running Model",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\nInputs\nDescription\n\n\n\n\nin_rasts\nList input that contains all the rasters that are chosen to be included in the model\n\n\npoly_inputs\nList input that contains the polygons that are chosen to be included in the model, if any\n\n\nref_raster\nSpatial raster input of the reference raster, which is used to align all of the other inputs. The DEM is usually a good choice here\n\n\nmodel_type\nString input indicating type of machine learning model. Options include “forest”, “tree”, “glm”, and “knn”\n\n\nclass_rast\nBinary parameter that determines whether the output will be probability rasters or a classification raster\n\n\nexport\nBinary parameter that determines whether or not the function exports the output to a file"
  },
  {
    "objectID": "run_model.html#executing-the-function",
    "href": "run_model.html#executing-the-function",
    "title": "Running Model",
    "section": "Executing the function",
    "text": "Executing the function\n\nprob_multi &lt;- run_model(multi_mod, \n                        in_rasts = c(elev1, elev2, elev3),\n                        ref_raster = dem)\n\n[1] \"Formatting inputs\"\n[1] \"Stacking rasters\"\n[1] \"Running model\"\n\n|---------|---------|---------|---------|\n=========================================\n                                          \n[1] \"Done!\"\n\nprob_simple &lt;- run_model(simple_mod, \n                        in_rasts = c(elev1, elev2, elev3),\n                        ref_raster = dem)\n\n[1] \"Formatting inputs\"\n[1] \"Stacking rasters\"\n[1] \"Running model\"\n[1] \"Done!\"\n\n\nThe function outputs a SpatRaster object has probabilisitic (or categorical) values and has the same extent (meaning) as the reference raster, as seen below.\n\n\nprob_simple\n\nclass       : SpatRaster \ndimensions  : 1287, 1557, 2  (nrow, ncol, nlyr)\nresolution  : 3.999648, 3.998959  (x, y)\nextent      : 551135.5, 557362.9, 5184713, 5189859  (xmin, xmax, ymin, ymax)\ncoord. ref. : NAD83 / UTM zone 10N (EPSG:26910) \nsource(s)   : memory\nnames       :  UPL,  WET \nmin values  : 0.12, 0.00 \nmax values  : 1.00, 0.88 \n\n\nBelow is how the output looks like on a map"
  },
  {
    "objectID": "run_model.html#classification-option",
    "href": "run_model.html#classification-option",
    "title": "Running Model",
    "section": "Classification Option",
    "text": "Classification Option\nInstead of returning probabilities, the run_model function also has an option to return a classification raster. This is often useful for when we testing the model to predict multiple types of wetlands (multi-class classification), since it is easier to comprehend one prediction rather than lots of probabilities.\n\nclass_multi &lt;- run_model(multi_mod, class_rast = TRUE,\n                        in_rasts = c(elev1, elev2, elev3),\n                        ref_raster = dem)\n\n[1] \"Formatting inputs\"\n[1] \"Stacking rasters\"\n[1] \"Running model\"\n[1] \"Done!\"\n\nclass_multi\n\nclass       : SpatRaster \ndimensions  : 1287, 1557, 1  (nrow, ncol, nlyr)\nresolution  : 3.999648, 3.998959  (x, y)\nextent      : 551135.5, 557362.9, 5184713, 5189859  (xmin, xmax, ymin, ymax)\ncoord. ref. : NAD83 / UTM zone 10N (EPSG:26910) \nsource(s)   : memory\ncategories  : class \nname        :                       class \nmin value   : Freshwater Emergent Wetland \nmax value   :                         UPL \n\n\nHere is what the output looks like on a map:"
  },
  {
    "objectID": "test.html#parameters",
    "href": "test.html#parameters",
    "title": "Testing model",
    "section": "Parameters",
    "text": "Parameters\nThe inputs for this function are almost the exactly the same as the build_model function, with one addition, kfold, the number of folds used in cross-validation.\n\n\n\n\n\n\n\nInputs\nDescriptions\n\n\n\n\nin_rasts\nList input that contains all the rasters that are chosen to be included in the model\n\n\npoly_inputs\nList input that contains the polygons that are chosen to be included in the model, if any\n\n\ntrain\nSpatial vector input of the training points\n\n\nref_raster\nSpatial raster input of the reference raster, which is used to align all of the other inputs. The DEM is usually a good choice here\n\n\nmodel_type\nString input indicating type of machine learning model. Options include “forest”, “tree”, “glm”, and “knn”\n\n\nmodel_params\nList input representing necessary parameters to the model. Depending on the model, it may require an extra input, such as the number of trees or number of neighbors.\n\n\nclass_field_name\nString input indicating the field where the wetland classification is. If calculated training points using the build_train_pts function above, this input may be skipped\n\n\nkfold\nNumeric input indicating number of folds data is split into. Represents number of times we test the model"
  },
  {
    "objectID": "test.html#examples-of-use",
    "href": "test.html#examples-of-use",
    "title": "Testing model",
    "section": "Examples of use",
    "text": "Examples of use\nThe function has the same inputs as the build_model functions. However, there is one more feature to customize, which is k_folds, or the number of times the cross validation is run. The default for the function is kfolds = 5\n\nCV_err(in_rasts = c(elev1, elev2, elev3), train = multi_pts,\n       ref_raster = dem)\n\n[1] \"Test Error Estimate: 33.3%\"\n[1] \"95% Confidence Interval: [32.3, 34.3]\"\n\nCV_err(in_rasts = c(elev1, elev2, elev3), train = simple_pts,\n       ref_raster = dem)\n\n[1] \"Test Error Estimate: 22.2%\"\n[1] \"95% Confidence Interval: [19.1, 25.4]\"\n\n\nAs we can tell above, the binary model is doing a much better job of prediction than the multi-class model"
  },
  {
    "objectID": "extra.html#visualizing-model",
    "href": "extra.html#visualizing-model",
    "title": "Extraneous Tips",
    "section": "Visualizing model",
    "text": "Visualizing model\nTo conduct basic plotting, it is easiest to just load in the terra package, as done below.\n\nlibrary(terra)\n\nterra 1.7.55\n\n\nNow, you can just type in the plot function and add the raster/vector object inside\n\nplot(prob_multi)\n\n\n\n\n\nplot(prob_simple)\n\n\n\n\nSince having both of these plots above is redundant, we can also choose to plot just one\n\nplot(prob_simple[\"WET\"])\n\n\n\n\nIf we want to be fun and add rainbow colors, type in rainbow(n), with n being the number of meadows. Since there are 5 different classes in class_multi, we will type in rainbow(5)\n\nplot(class_multi, col = rainbow(5))\n\n\n\n\nAlso can choose the color for each class. Here is a description of all the colors that can be used\n\nplot(class_multi, col = c(\"lightblue\", \"forestgreen\", \"dodgerblue\", \"darkblue\", \"wheat\"))\n\n\n\n\nYou can also add labels to the plots as well. Adding a title just requires an input of main and adding x and y labels just require inputs for xlab and ylab, respectively (though x and y labels are less important in spatial plotting).\nAnother thing that you can try is changing the legend. We can see from the above plots that the names for the values are simply too long for the legend. To improve on this, we need to add the add_legend() function in terra after plot(). The inputs of this are the position of the legend (should be typed in first), the labels for the legend, and the colors that are depicted (can just copy/paste from plot). A few other inputs are cex (legend size) and lwd (line width), both of which can be chosen by trial and error. Also, in order to prevent having multiple legends, type legend = FALSE into plot().\n\nplot(class_multi, main = \"Predicted Wetland\", xlab = \"x\",\n     ylab = \"y\", col = c(\"lightblue\", \"forestgreen\", \"dodgerblue\", \"darkblue\", \"wheat\"), legend = FALSE)\nadd_legend(\"bottomleft\",\n           legend=c(\"Emergent\", \"Forested/Shrub\", \"Pond\",\n                    \"Riverine\", \"Upland\"),\n           col= c(\"lightblue\", \"forestgreen\", \"dodgerblue\", \"darkblue\", \"wheat\"), cex = 0.8, lwd = 2)\n\n\n\n\n\nMore advanced plotting\nIf you desire more advanced and more customizable plots, then that is what the tidyterra package is for. More information on this package, including how it is used, can be found here. The package includes data manipulation features, which you might find interesting, but is not within the scope of the WIP tool."
  },
  {
    "objectID": "extra.html#export",
    "href": "extra.html#export",
    "title": "Extraneous Tips",
    "section": "Export",
    "text": "Export\nSay you to take the outputs, whether they are the probability rasters or the gradient, and be able to use or see them outside of R. This could be so you can take a look at them using a GIS software or so you can share your results. Whatever the reason, there are a number of ways to do this.\nAs mentioned above, many of the functions, such as surface_met and run_model, have export options (using the executable files exports them automatically). As such, the only action needed to be done in order to have an exported file would be to type in export = T.\nHowever if that did not happen, then no worries, here is a guide to exporting on your own. For this, we will use the terra::writeRaster() function, which requires two inputs: the R input we want to export and the name of the exported file. Below we will export the class_multi raster into a file named PF_class.tif\n\nterra::writeRaster(class_multi, filename = \"PF_class.tif\")\n\nThis file ends up in the current working directory. To find what directory you are in, run the function getwd(). To change the working directory, at the top of the screen, click on Session -&gt; Set Working Directory -&gt; Choose Directory.\nAnother way to choose where the exported file ends up is to type in the full directory into the filename input. This is shown below:\n\nterra::writeRaster(class_multi,\n                   filename = \"C:Projects/WIP/PF_class.tif\")\n\nOne last thing to note is for how to export when the object contains more than one raster inside. This happens above with objects like prob_multi, elev1, and elev2 (among others). To export these correctly, you will need to export each raster one at a time. This is done by adding a $ after the variable name, and then typing the name of the specific raster after, as shown below:\n\nterra::writeRaster(prob_multi$Pond, filename = \"Pond.tif\")\nterra::writeRaster(prob_multi$Riverbed, filename = \"River.tif\")\nterra::writeRaster(prob_multi$Water, filename = \"Water.tif\")"
  },
  {
    "objectID": "extra.html#errors",
    "href": "extra.html#errors",
    "title": "Extraneous Tips",
    "section": "Errors",
    "text": "Errors\nAs always in dealing with any sort of computer processing, it is just a matter of time until an error message pops up. This section covers some of the more common errors that may show up when running the WIP tool that are also not easily explained by the error message.\n\nIf you are typing in a file directory and use “\\” (backslash) once when acknowledging the break between files, R will throw an error such as '\\P' is an unrecognized escape in character string (the P is a placeholder for whatever letter is after the backslash)\nstd::bad_aloc is a memory error, meaning whatever R is trying to do is taking up too much memory for the computer to handle. Apart from just using a computer with more memory, the best way to solve this is to split up the area you are running into multiple parts, run each of the parts one at a time, and then mosaic them together afterwards.\nNo wetlands to sample is an error from the build_train_pts function. Aside from the wetlands file actually being empty, there are two possible issues:\n\nIncorrect input in wet_types, meaning that the function is searching for wetlands that are actually not there\nIncorrect input in wet_field, which means that the function can’t find where the types of wetlands are listed. This will happen when the wetlands are from a different database than NWI. To figure out what the field name is, try using the names() function and then see which field is most likely to contain the wetland types, then type that into wet_field\n\n\nHowever, if a different error shows up, keep in mind that usually the best way to solve an error is to copy the error message R puts up, and then paste it into a search engine. It might seem like a cheat and a bit lazy, but it is a very successful debugging tactic."
  },
  {
    "objectID": "functions.html",
    "href": "functions.html",
    "title": "Functions",
    "section": "",
    "text": "This section contains the code for all of the functions mentioned throughout this whole book. As a review, a list of all of these functions is below:\n\nbuild_train_pts\nsurface_met1\nsurface_met2\nbuild_model\nrun_model\nCV_err\n\nTo use these functions are your device, either click the Functions link under the Downloads tab in the right corner, which downloads an .RData file containing them and can be loaded using the load function, or copy/paste each of these sectiona into your own R session"
  },
  {
    "objectID": "train_pts_fun.html",
    "href": "train_pts_fun.html",
    "title": "build_train_pts",
    "section": "",
    "text": "build_train_pts &lt;- function(region_poly, wet_poly, multi_class = FALSE,\n                            wet_types = c(\"Freshwater Forested/Shrub Wetland\",\n                                          \"Freshwater Emergent Wetland\",\n                                          \"Freshwater Pond\",\n                                          \"Estuarine and Marine Wetland\",\n                                          \"Riverine\", \"Lake\",\n                                          \"Estuarine and Marine Deepwater\",\n                                          \"Other\"),\n                            wet_field = \"WETLAND_TY\",\n                            sample_points = c(50, 150), \n                            export = FALSE) {\n  \n  # Loads in polygons if input is a file name\n  if(is.character(wet_poly[[1]])) {\n    temp_poly &lt;- list()\n    for(i in 1:length(wet_poly)) {\n      temp_poly[[i]] &lt;- terra::vect(wet_poly) \n    }\n    wet_poly &lt;- temp_poly\n  }\n  \n  if(is.character(region_poly)) {\n    region_poly &lt;- terra::vect(region_poly)\n  }\n  \n  # Filters the wetland polygons to only include wanted types\n  wet_poly &lt;- wet_poly[unlist(wet_poly[[wet_field]]) %in% wet_types]\n  if(length(wet_poly) == 0) {\n    stop(\"No wetlands to sample!\")\n  }\n  \n  # Cropping the wetland polygon(s) to the overall region\n  wet_poly &lt;- terra::project(wet_poly, region_poly)\n  wet_poly &lt;- terra::crop(wet_poly, region_poly)\n  \n  # Checks if output is supposed to be more than two classes before proceeding\n  if(multi_class) {\n    # Initialize parameters\n    train_crds &lt;- NULL\n    train_atts &lt;- c()\n    wet_samp &lt;- sample_points[1]\n    up_samp &lt;- sample_points[2]\n    \n    # Sample points for each wetland class\n    for(i in 1:length(wet_types)) {\n      temp_poly &lt;- wet_poly[unlist(wet_poly[[wet_field]]) == wet_types[i]]\n      \n      # Checking if polygons of that type of wetland exist\n      if(length(temp_poly) == 0) {\n        warning(paste0(wet_types[i], \" not found!\"))\n      }\n      else {\n        wet_crds &lt;- NULL\n        samp_wet_pts &lt;- terra::spatSample(temp_poly, wet_samp)\n        coords &lt;- terra::crds(samp_wet_pts)\n        wet_crds &lt;- rbind(wet_crds, coords)\n        \n        num_coords &lt;- nrow(coords)\n        while(num_coords &lt; wet_samp) {\n          new_points &lt;- terra::spatSample(temp_poly,\n                                          wet_samp-(num_coords))\n          new_crds &lt;- terra::crds(new_points)\n          wet_crds &lt;- rbind(wet_crds, new_crds)\n          num_coords &lt;- num_coords + nrow(new_crds)\n        }\n        \n        train_crds &lt;- rbind(train_crds, wet_crds)\n        train_atts &lt;- c(train_atts, rep(wet_types[i], wet_samp))\n      }\n    }\n    \n    # Sample points from non-wetland areas\n    up_poly &lt;- terra::erase(region_poly, wet_poly)\n    samp_up_pts &lt;- terra::spatSample(up_poly, up_samp)\n    up_crds &lt;- terra::crds(samp_up_pts)\n    \n    # Create the points\n    train_crds &lt;- rbind(train_crds, up_crds)\n    train_atts &lt;- c(train_atts, rep(\"UPL\", up_samp))\n    train_atts &lt;- data.frame(class = factor(train_atts))\n    pts &lt;- terra::vect(train_crds, atts = train_atts,\n                       crs = terra::crs(region_poly))\n  } else {\n    # Sample the wetland points\n    wet_samp &lt;- sample_points[1]\n    up_samp &lt;- sample_points[2]\n    wet_crds &lt;- NULL\n    \n    num_points &lt;- c()\n    total_area &lt;- sum(terra::expanse(wet_poly))\n    for(i in 1:length(wet_types)) {\n      temp_poly &lt;- wet_poly[unlist(wet_poly[[wet_field]]) == wet_types[i]]\n      \n      # Checking if polygons of that type of wetland exist\n      if(length(temp_poly) == 0) {\n        warning(paste0(wet_types[i], \" not found!\"))\n      }\n      else {\n        prop_area &lt;- sum(terra::expanse(temp_poly)) / total_area\n        num_points[i] &lt;- round(prop_area * wet_samp)\n        if(num_points[i] != 0) {\n          samp_wet_pts &lt;- terra::spatSample(temp_poly,\n                                            num_points[i])\n          coords &lt;- terra::crds(samp_wet_pts)\n          wet_crds &lt;- rbind(wet_crds, coords)\n          num_coords &lt;- nrow(coords)\n          while(num_coords &lt; num_points[i]) {\n            new_points &lt;- terra::spatSample(temp_poly,\n                                            num_points[i]-(num_coords))\n            new_crds &lt;- terra::crds(new_points)\n            wet_crds &lt;- rbind(wet_crds, new_crds)\n            num_coords &lt;- num_coords + nrow(new_crds)\n          }\n        }\n      }\n    }\n    if(sum(num_points, na.rm = T) != wet_samp) {\n      stop(\"Please try another sample size\")\n    }\n    \n    # Sample points from non-wetland areas\n    up_poly &lt;- terra::erase(region_poly, wet_poly)\n    samp_up_pts &lt;- terra::spatSample(up_poly, up_samp)\n    up_crds &lt;- terra::crds(samp_up_pts)\n    \n    # Create the points\n    train_crds &lt;- rbind(wet_crds, up_crds)\n    train_atts &lt;- data.frame(class = factor(c(rep(\"WET\", wet_samp),\n                                              rep(\"UPL\", up_samp))))\n    pts &lt;- terra::vect(train_crds, atts = train_atts,\n                       crs = terra::crs(region_poly))\n  }\n  \n  # Return the points and exports them, if desired\n  if(export) {\n    terra:writeVector(pts, filename = \"trainingdata.shp\")\n  }\n  \n  return(pts)\n}"
  },
  {
    "objectID": "fun_s1.html",
    "href": "fun_s1.html",
    "title": "surface_met1",
    "section": "",
    "text": "surface_met1 &lt;- function(len, metrics = c(\"grad\", \"plan\", \"prof\", \"dev\"),\n                         dem_dir, exec_dir, out_dir=getwd(), re_sample = NA) {\n  \n  # Checking to see if directories exist\n  if(!file.exists(dem_dir)) {\n    stop(\"DEM directory does not exist!\")\n  }\n  \n  if(!dir.exists(exec_dir)) {\n    stop(\"Executable Files directory does not exist!\")\n  }\n  \n  # Prepare inputs\n  dem_dir &lt;- normalizePath(dem_dir)\n  out_dir &lt;- normalizePath(out_dir)\n  if(!endsWith(out_dir, \"\\\\\")) {\n    out_dir &lt;- paste0(out_dir, \"\\\\\")\n  }\n  exec_dir &lt;- normalizePath(exec_dir)\n  \n  # Write input file\n  file_name &lt;- paste0(out_dir, \"input_makeGrids.txt\")\n  file.create(file_name)\n  \n  writeLines(c(\"# Input file for makeGrids\",\n               \"\",\n               paste0(\"DEM: \", dem_dir),\n               paste0(\"SCRATCH DIRECTORY: \", out_dir),\n               paste0(\"LENGTH SCALE: \", len)), con = file_name)\n  \n  if(\"grad\" %in% metrics) {\n    write(paste0(\"GRID: GRADIENT, OUTPUT FILE = \", out_dir, \"grad\", len, \".flt\"),\n          file = file_name, append = T) \n  }\n  \n  if(\"plan\" %in% metrics) {\n    write(paste0(\"GRID: PLAN CURVATURE, OUTPUT FILE = \", out_dir,\n                 \"plan\", len), file = file_name, append = T)\n  }\n  \n  if(\"prof\" %in% metrics) {\n    write(paste0(\"GRID: PROFILE CURVATURE, OUTPUT FILE = \", out_dir,\n                 \"prof\", len), file = file_name, append = T)\n  }\n  \n  # Run surface metrics sans DEV\n  system(paste0(exec_dir, \"\\\\makeGrids\"), input = file_name)\n  \n  # Writing input file for DEV\n  if (\"dev\" %in% metrics) {\n    if(is.na(re_sample)) {\n      stop(\"Set re_sample level\")\n    }\n    \n    # Prepare inputs\n    file_name &lt;- paste0(out_dir, \"input_localRelief.txt\")\n    rad &lt;- len / 2\n    \n    # Create and write input file\n    file.create(file_name)\n    writeLines(c(\"# Input file for LocalRelief\",\n                 \"# Creating by surfaceMetrics.R\",\n                 paste0(\"# On \", Sys.time()),\n                 paste0(\"DEM: \", dem_dir),\n                 paste0(\"SCRATCH DIRECTORY: \", out_dir),\n                 paste0(\"RADIUS: \", rad),\n                 paste0(\"DOWN SAMPLE: \", re_sample),\n                 paste0(\"SAMPLE INTERVAL: \", re_sample),\n                 paste0(\"OUTPUT LOCAL RASTER: \", out_dir, \"local\", len)),\n               con = file_name)\n    \n    # Run DEV in console\n    system(paste0(exec_dir, \"\\\\localRelief\"), input = file_name)\n  }\n}"
  },
  {
    "objectID": "fun_s.html",
    "href": "fun_s.html",
    "title": "surface_met",
    "section": "",
    "text": "surface_met &lt;- function(DEM, len, export = FALSE,\n                        elev_dev = c(\"grad\", \"plan\", \"prof\", \"dev\", \"twi\")) {\n  # Checks if inputs are file names and loads them in\n  if(is.character(DEM)) {\n    if(!file.exists(DEM)) {\n      stop(\"Cannot find DEM file\")\n    }\n    DEM &lt;- terra::rast(DEM)\n  }\n  # Sets up the resolution\n  k &lt;- round(len/terra::res(DEM)[1])\n  if (k %% 2 == 0) {\n    k &lt;- k + 1\n  }\n  \n  # Initialize the inputs for the model\n  in_rast &lt;- list()\n  \n  if(\"grad\" %in% elev_dev) {\n    j &lt;- k/2 - 0.5\n    \n    xl.end &lt;- matrix(c(1, rep(NA_real_, times=k-1)), ncol=k, nrow=1)\n    xr.end &lt;- matrix(c(rep(NA_real_, times=k-1), 1), ncol=k, nrow=1)\n    \n    x.mids &lt;- matrix(NA_real_, ncol=k, nrow=j-1)\n    \n    xl.mid &lt;- matrix(c(2, rep(NA_real_, times=k-1)), ncol=k, nrow=1)\n    xr.mid &lt;- matrix(c(rep(NA_real_, times=k-1), 2), ncol=k, nrow=1)\n    \n    xl.mat &lt;- rbind(xl.end, x.mids, xl.mid, x.mids, xl.end)\n    xr.mat &lt;- rbind(xr.end, x.mids, xr.mid, x.mids, xr.end)\n    \n    yt.end &lt;- matrix(c(1, rep(NA_real_, times=k-1)), ncol=1, nrow=k)\n    yb.end &lt;- matrix(c(rep(NA_real_, times=k-1), 1), ncol=1, nrow=k)\n    \n    y.mids &lt;- matrix(NA_real_, ncol=j-1, nrow=k)\n    \n    yt.mid &lt;- matrix(c(2, rep(NA_real_, times=k-1)), ncol=1, nrow=k)\n    yb.mid &lt;- matrix(c(rep(NA_real_, times=k-1), 2), ncol=1, nrow=k)\n    \n    yt.mat &lt;- cbind(yt.end, y.mids, yt.mid, y.mids, yt.end)\n    yb.mat &lt;- cbind(yb.end, y.mids, yb.mid, y.mids, yb.end)\n    \n    dz.dx.l &lt;- terra::focal(DEM, xl.mat, fun=sum, na.rm=T, na.policy = \"omit\")\n    dz.dx.r &lt;- terra::focal(DEM, xr.mat, fun=sum, na.rm=T, na.policy = \"omit\")\n    dz.dy.t &lt;- terra::focal(DEM, yt.mat, fun=sum, na.rm=T, na.policy = \"omit\")\n    dz.dy.b &lt;- terra::focal(DEM, yb.mat, fun=sum, na.rm=T, na.policy = \"omit\")\n    \n    wts.l &lt;- terra::focal(!is.na(DEM), w=xl.mat, fun=sum, na.rm=TRUE,\n                          na.policy = \"omit\")\n    wts.r &lt;- terra::focal(!is.na(DEM), w=xr.mat, fun=sum, na.rm=TRUE,\n                          na.policy = \"omit\")\n    wts.t &lt;- terra::focal(!is.na(DEM), w=yt.mat, fun=sum, na.rm=TRUE,\n                          na.policy = \"omit\")\n    wts.b &lt;- terra::focal(!is.na(DEM), w=yb.mat, fun=sum, na.rm=TRUE,\n                          na.policy = \"omit\")\n    dz.dx &lt;- ((dz.dx.r/wts.r) - (dz.dx.l/wts.l))/(2*j*terra::xres(DEM))\n    dz.dy &lt;- ((dz.dy.t/wts.t) - (dz.dy.b/wts.b))/(2*j*terra::yres(DEM))\n    \n    grad &lt;- sqrt(dz.dx^2 + dz.dy^2)\n    in_rast &lt;- c(in_rast, grad)\n    \n    names(in_rast)[length(in_rast)] &lt;- paste0(\"grad\", len)\n  }\n  \n  if(\"plan\" %in% elev_dev) {\n    if (\"prof\" %in% elev_dev) {\n      both &lt;- MultiscaleDTM::Qfit(DEM, metrics = c(\"planc\", \"profc\"),\n                                  w = k, na.rm = T)\n      in_rast &lt;- c(in_rast, both[[1]], both[[2]])\n      \n      names(in_rast)[length(in_rast)-1] &lt;- paste0(\"plan\", len)\n      names(in_rast)[length(in_rast)] &lt;- paste0(\"prof\", len)\n    } else {\n      plan &lt;- MultiscaleDTM::Qfit(DEM, metrics = \"planc\", w = k, na.rm = T)\n      in_rast &lt;- c(in_rast, plan)\n      \n      names(in_rast)[length(in_rast)] &lt;- paste0(\"plan\", len)\n    }\n  } else if(\"prof\" %in% elev_dev) {\n    prof &lt;- MultiscaleDTM::Qfit(DEM, metrics = \"profc\", w = k, na.rm = T)\n    in_rast &lt;- c(in_rast, prof)\n    \n    names(in_rast)[length(in_rast)] &lt;- paste0(\"prof\", len)\n  }\n  \n  if(\"dev\" %in% elev_dev) {\n    dev &lt;- (DEM - focal(DEM, w = k, fun = \"mean\", na.rm = T, na.policy = \"omit\")) / focal(DEM, w = k, fun = \"sd\", na.rm = T, na.policy = \"omit\") \n    in_rast &lt;- c(in_rast, rast_dev)\n    \n    names(in_rast)[length(in_rast)] &lt;- paste0(\"dev\", len)\n  }\n  \n  if(\"twi\" %in% elev_dev) {\n    topidx &lt;- topmodel::topidx(terra::as.matrix(DEM), res = terra::res(DEM)[1])\n    a &lt;- terra::setValues(DEM, topidx$area)\n    twi &lt;- a / tan(terra::terrain(DEM, unit = \"radians\"))\n    terra::values(twi) &lt;- ifelse(terra::values(twi) &lt; 0, 0, terra::values(twi))\n    twi &lt;- terra::focal(twi, w = k, mean, na.rm = T, na.policy = \"omit\")\n    \n    in_rast &lt;- c(in_rast, twi)\n    \n    names(in_rast)[length(in_rast)] &lt;- paste0(\"twi\", len)\n  }\n  \n  # Exports the surface metrics\n  if(export) {\n    for(i in 1:length(in_rast)) {\n      writeRaster(in_rast[[i]],\n                  filename = paste0(names(in_rast[i]), len, \".tif\"))\n    }\n  }\n  return(in_rast)\n}"
  },
  {
    "objectID": "build_model_fun.html",
    "href": "build_model_fun.html",
    "title": "build_model",
    "section": "",
    "text": "build_model &lt;- function(in_rasts, poly_inputs = list(), train, ref_raster,\n                        model_type = \"forest\", model_params = list(ntree = 200),\n                        class_field_name = \"class\") {\n  \n  # Checking if input rasters are file names, then load them in\n  if(is.character(in_rasts[1])) {\n    temp_rast &lt;- rep(list(), length(in_rasts))\n    for(i in 1:length(in_rasts)) {\n      temp_rast[[i]] &lt;- terra::rast(in_rasts[i])\n    }\n    names(temp_rast) &lt;- in_rasts\n    in_rasts &lt;- temp_rast\n  }\n  \n  # Checks if there are any polygon inputs\n  if(length(poly_inputs) &gt; 0) {\n    \n    # Checking to see the polygon inputs are filenames\n    if(is.character(poly_inputs[[1]])) {\n      temp_poly &lt;- rep(list(), length(poly_inputs))\n      for(i in 1:length(poly_inputs)) {\n        if(!file.exists(poly_inputs[[i]])) {\n          stop(paste0(\"Cannot find poly input file:\", poly_inputs[i]))\n        }\n        temp_poly[[i]] &lt;- terra::vect(poly_inputs[i]) \n      }\n      names(temp_poly) &lt;- poly_inputs\n      poly_inputs &lt;- temp_poly\n    }\n    \n    # Rasterize polygon inputs\n    for(i in 1:length(poly_inputs)) {\n      vr_name &lt;- names(poly_inputs)[i]\n      temp_rast &lt;- terra::rasterize(poly_inputs[i], ref_raster, field = vr_name)\n      in_rasts &lt;- c(in_rasts, temp_rast)\n    }\n  }\n  \n  # Ensure that all inputs are covering the same area\n  print(\"Formatting inputs\")\n  for(i in 1:length(in_rasts)) {\n    in_rasts[[i]] &lt;- terra::project(in_rasts[[i]], ref_raster)\n    in_rasts[[i]] &lt;- terra::crop(in_rasts[[i]], ref_raster)\n  }\n  \n  \n  # Set up training data\n  print(\"Setting up training data\")\n  train &lt;- terra::project(train, ref_raster)\n  df_train &lt;- data.frame(class = factor(as.vector(unlist(train[[class_field_name]]))))\n  for(i in 1:length(in_rasts)) {\n    vals &lt;- terra::extract(in_rasts[[i]], train, ID = F)\n    df_train &lt;- cbind(df_train, vals)\n  }\n  df_train &lt;- na.omit(df_train)\n  colnames(df_train) &lt;- c(\"class\", names(in_rasts))\n  \n  # Build the model\n  print(\"Building model\")\n  if(model_type == \"forest\"){\n    mod &lt;- randomForest::randomForest(class ~ ., data = df_train, \n                                      ntree = model_params$ntree)\n  } else if (model_type == \"tree\") {\n    mod &lt;- randomForest::randomForest(class ~ ., data = df_train, ntree = 1)\n  } else if(model_type == \"glm\") {\n    if(length(levels(df_train$class)) &gt; 2) {\n      mod &lt;- nnet::multinom(class ~ ., data = df_train)\n    } else {\n      mod &lt;- glm(class ~ ., data = df_train, family = \"binomial\")\n    }\n  } else if(model_type == \"knn\") {\n    mod &lt;- caret::knn3(formula = class ~ ., data = df_train, k = model_params$k)\n  } else {\n    stop(\"Incorrect model type\")\n  }\n  \n  print(\"Done!\")\n  return(mod)\n}"
  },
  {
    "objectID": "run_model_fun.html",
    "href": "run_model_fun.html",
    "title": "run_model",
    "section": "",
    "text": "run_model &lt;- function(mod, in_rasts = list(), poly_inputs = list(), ref_raster,\n                      model_type = \"forest\", class_rast = FALSE,\n                      export = FALSE) {\n  \n  # Checking if inputs are file names, then load them in\n  if(is.character(in_rasts[1])) {\n    temp_rast &lt;- rep(list(), length(in_rasts))\n    for(i in 1:length(in_rasts)) {\n      temp_rast[[i]] &lt;- terra::rast(in_rasts[i])\n    }\n    names(temp_rast) &lt;- in_rasts\n    in_rasts &lt;- temp_rast\n  }\n  \n  if(length(poly_inputs) &gt; 0) {\n    if(is.character(poly_inputs[[1]])) {\n      temp_poly &lt;- rep(list(), length(poly_inputs))\n      for(i in 1:length(poly_inputs)) {\n        if(!file.exists(poly_inputs[[i]])) {\n          stop(paste0(\"Cannot find poly input file:\", poly_inputs[i]))\n        }\n        temp_poly[[i]] &lt;- terra::vect(poly_inputs[i]) \n      }\n      names(temp_poly) &lt;- poly_inputs\n      poly_inputs &lt;- temp_poly\n    }\n    for(i in 1:length(poly_inputs)) {\n      vr_name &lt;- names(poly_inputs)[i]\n      temp_rast &lt;- terra::rasterize(poly_inputs[i], ref_raster, field = vr_name)\n      in_rasts &lt;- c(in_rasts, temp_rast)\n    }\n  }\n  \n  # Ensure that all inputs are covering the same area\n  print(\"Formatting inputs\")\n  for(i in 1:length(in_rasts)) {\n    in_rasts[[i]] &lt;- terra::project(in_rasts[[i]], ref_raster)\n    in_rasts[[i]] &lt;- terra::crop(in_rasts[[i]], ref_raster)\n  }\n  \n  # Stacks the rasters on top of each other to create one raster\n  print(\"Stacking rasters\")\n  input_raster &lt;- in_rasts[[1]]\n  if(length(in_rasts) &gt; 1) {\n    for(i in 2:length(in_rasts)) {\n      input_raster &lt;- c(input_raster, in_rasts[[i]])\n    }\n  }\n  names(input_raster) &lt;- names(in_rasts)\n  \n  # Run the model\n  print(\"Running model\")\n  \n  if(class_rast) {\n    if(isTRUE(mod$call[[1]] == \"glm\")) {\n      output &lt;- terra::predict(input_raster, mod, na.rm = T,\n                               type = \"response\")\n      vals &lt;- terra::values(output)\n      vals &lt;- ifelse(vals &gt; 0.5, \"WET\", \"UPL\")\n      terra::values(output) &lt;- vals\n      \n    } else {\n      output &lt;- terra::predict(input_raster, mod, na.rm = T)\n    }\n    \n  } else {\n    if(isTRUE(mod$call[[1]] == \"glm\")) {\n      output &lt;- terra::predict(input_raster, mod, na.rm = T,\n                               type = \"response\")\n    } else {\n      output &lt;- terra::predict(input_raster, mod, na.rm = T, type = \"prob\")\n    }\n  }  \n  \n  if(export) {\n    for(i in 1:length(output)) {\n      file_name &lt;- paste0(names(input_raster)[i], \"prob.tif\")\n      terra::writeRaster(output[[i]], filename = file_name)\n    }\n  }\n  \n  print(\"Done!\")\n  return(output)\n}"
  },
  {
    "objectID": "cv_err_fun.html",
    "href": "cv_err_fun.html",
    "title": "CV_err",
    "section": "",
    "text": "CV_err &lt;- function(in_rasts, poly_inputs = list(), ref_raster,\n                   model_type = \"forest\", model_params = list(ntree = 200), \n                   train, kfold= 5, class_field_name = \"class\") {\n  \n  # Checking if inputs are file names, then load them in\n  if(is.character(in_rasts[1])) {\n    temp_rast &lt;- rep(list(), length(in_rasts))\n    for(i in 1:length(in_rasts)) {\n      temp_rast[[i]] &lt;- terra::rast(in_rasts[i])\n    }\n    names(temp_rast) &lt;- in_rasts\n    in_rasts &lt;- temp_rast\n  }\n\n  if(length(poly_inputs) &gt; 0) {\n    if(is.character(poly_inputs[[1]])) {\n      temp_poly &lt;- rep(list(), length(poly_inputs))\n      for(i in 1:length(poly_inputs)) {\n        if(!file.exists(poly_inputs[[i]])) {\n          stop(paste0(\"Cannot find poly input file:\", poly_inputs[i]))\n        }\n        temp_poly[[i]] &lt;- terra::vect(poly_inputs[i]) \n      }\n      names(temp_poly) &lt;- poly_inputs\n      poly_inputs &lt;- temp_poly\n    }\n  }\n  \n  # Convert the polygons into rasters\n  if(length(poly_inputs) &gt; 0) {\n    for(i in 1:length(poly_inputs)) {\n      vr_name &lt;- names(poly_inputs)[i]\n      temp_rast &lt;- terra::rasterize(poly_inputs[i], ref_raster, field = vr_name)\n      in_rasts &lt;- c(in_rasts, temp_rast)\n    }\n  }\n  \n  # Ensure that all inputs are covering the same area\n  for(i in 1:length(in_rasts)) {\n    in_rasts[[i]] &lt;- terra::project(in_rasts[[i]], ref_raster)\n    in_rasts[[i]] &lt;- terra::crop(in_rasts[[i]], ref_raster)\n  }\n  \n  # Set up training data\n  train &lt;- terra::project(train, ref_raster)\n  df_train &lt;- data.frame(class = factor(as.vector(unlist(train[[class_field_name]]))))\n  for(i in 1:length(in_rasts)) {\n    vals &lt;- terra::extract(in_rasts[[i]], train, ID = F)\n    df_train &lt;- cbind(df_train, vals)\n  }\n  df_train &lt;- na.omit(df_train)\n  colnames(df_train) &lt;- c(\"class\", names(in_rasts))\n  \n  k &lt;- kfold\n  test_err &lt;- c()\n  index &lt;- sample(k, nrow(df_train), replace = T)\n  \n  for(i in 1:k) {\n    train_df &lt;- df_train[index != i,]\n    test_df &lt;- df_train[index == i,]\n    y_test &lt;- test_df$class\n    \n    if(model_type == \"forest\"){\n      mod &lt;- randomForest::randomForest(class ~ ., data = train_df, \n                                        ntree = model_params$ntree)\n    } else if (model_type == \"tree\") {\n      mod &lt;- randomForest::randomForest(class ~ ., data = train_df, ntree = 1)\n    } else if(model_type == \"glm\") {\n      if(length(levels(df_train$class)) &gt; 2) {\n        mod &lt;- nnet::multinom(class ~ ., data = train_df)\n      } else {\n        mod &lt;- glm(class ~ ., data = train_df, family = \"binomial\")\n      }\n    } else if(model_type == \"knn\") {\n      mod &lt;- caret::knn3(formula = class ~ ., data = train_df,\n                         k = model_params$k)\n    } else {\n      stop(\"Incorrect model type\")\n    }\n    \n    if(model_type == \"glm\") {\n      pred &lt;- predict(mod, newdata = test_df, type = \"response\")\n    } else {\n      pred &lt;- predict(mod, newdata = test_df)\n    }\n    test_err[i] &lt;- mean(pred != y_test)\n  }\n  mean_err &lt;- mean(test_err)\n  ci_err &lt;- round(100 * (mean_err + c(-1, 1)*qnorm(0.975)*sd(test_err)/k), 1)\n  print(paste0(\"Test Error Estimate: \", round(mean_err * 100, 1), \"%\"))\n  print(paste0(\"95% Confidence Interval: [\", ci_err[1], \", \", ci_err[2], \"]\"))\n}"
  }
]